{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigsaw_Unintended_Bias_in_Toxicity_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GioLomia/Jigsaw_Speach_Toxicity_Classifier/blob/master/Jigsaw_Unintended_Bias_in_Toxicity_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hE1jYCDUZ6Ng",
        "colab_type": "code",
        "outputId": "020ee6fa-c0b3-49f8-dbd5-3f90d259af44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Bidirectional\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_2A2_MR3aEPQ",
        "colab_type": "code",
        "outputId": "f2f8114d-40bb-4039-a82d-66545e00594a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zqo1ctknaIpD",
        "colab_type": "code",
        "outputId": "1d8870df-ca33-48c2-daf9-5896c14e3e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!ls\n",
        "!kaggle competitions list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data\n",
            "ref                                                deadline             category            reward  teamCount  userHasEntered  \n",
            "-------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                                   2030-01-01 00:00:00  Getting Started  Knowledge       2571            True  \n",
            "titanic                                            2030-01-01 00:00:00  Getting Started  Knowledge      10418           False  \n",
            "house-prices-advanced-regression-techniques        2030-01-01 00:00:00  Getting Started  Knowledge       4326           False  \n",
            "imagenet-object-localization-challenge             2029-12-31 07:00:00  Research         Knowledge         36           False  \n",
            "competitive-data-science-predict-future-sales      2019-12-31 23:59:00  Playground           Kudos       2630           False  \n",
            "two-sigma-financial-news                           2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "aerial-cactus-identification                       2019-07-08 23:59:00  Playground       Knowledge        202           False  \n",
            "jigsaw-unintended-bias-in-toxicity-classification  2019-06-26 23:59:00  Featured           $65,000         44            True  \n",
            "inaturalist-2019-fgvc6                             2019-06-10 23:59:00  Research             Kudos          4           False  \n",
            "iwildcam-2019-fgvc6                                2019-06-07 23:59:00  Playground           Kudos         27           False  \n",
            "imet-2019-fgvc6                                    2019-06-04 23:59:00  Research             Kudos         42           False  \n",
            "LANL-Earthquake-Prediction                         2019-06-03 23:59:00  Research           $50,000       2140            True  \n",
            "tmdb-box-office-prediction                         2019-05-30 23:59:00  Playground       Knowledge        546           False  \n",
            "dont-overfit-ii                                    2019-05-07 23:59:00  Playground            Swag       1334           False  \n",
            "ciphertext-challenge-ii                            2019-04-25 23:59:00  Playground            Swag         12           False  \n",
            "data-science-for-good-careervillage                2019-04-23 23:59:00  Analytics          $15,000          0            True  \n",
            "gendered-pronoun-resolution                        2019-04-22 23:59:00  Research           $25,000        564           False  \n",
            "petfinder-adoption-prediction                      2019-04-18 23:59:00  Featured           $25,000       2010            True  \n",
            "career-con-2019                                    2019-04-11 23:59:00  Recruitment           Swag       1063            True  \n",
            "santander-customer-transaction-prediction          2019-04-10 23:59:00  Featured           $65,000       8079            True  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CrG3XMwOabtQ",
        "colab_type": "code",
        "outputId": "90e20da2-4a50-4738-e752-e4c9a28f420a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions files -c jigsaw-unintended-bias-in-toxicity-classification\n",
        "!ls\n",
        "!kaggle competitions download  -c jigsaw-unintended-bias-in-toxicity-classification -p /content/kaggle\n",
        "!mkdir root\n",
        "%cd kaggle\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name                    size  creationDate         \n",
            "---------------------  -----  -------------------  \n",
            "sample_submission.csv    1MB  2019-03-28 21:16:21  \n",
            "test.csv                29MB  2019-03-28 21:16:21  \n",
            "train.csv              778MB  2019-03-28 21:16:18  \n",
            "adc.json  sample_data\n",
            "Downloading sample_submission.csv.zip to /content/kaggle\n",
            "  0% 0.00/221k [00:00<?, ?B/s]\n",
            "100% 221k/221k [00:00<00:00, 68.2MB/s]\n",
            "Downloading test.csv.zip to /content/kaggle\n",
            " 41% 5.00M/12.1M [00:00<00:00, 35.6MB/s]\n",
            "100% 12.1M/12.1M [00:00<00:00, 59.1MB/s]\n",
            "Downloading train.csv.zip to /content/kaggle\n",
            " 95% 258M/273M [00:02<00:00, 152MB/s]\n",
            "100% 273M/273M [00:02<00:00, 101MB/s]\n",
            "/content/kaggle\n",
            "sample_submission.csv.zip  test.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ymAvbzdZapG2",
        "colab_type": "code",
        "outputId": "c99de88b-cc31-42b6-8424-47e97529e1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/kaggle/train.csv.zip\n",
        "!unzip /content/kaggle/test.csv.zip\n",
        "!unzip /content/kaggle/sample_submission.csv.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle/train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  /content/kaggle/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  /content/kaggle/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "sample_submission.csv\t   test.csv\t train.csv\n",
            "sample_submission.csv.zip  test.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kpd3TgzRcQ0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"/content/kaggle/train.csv\")\n",
        "test=pd.read_csv(\"/content/kaggle/test.csv\")\n",
        "sample=pd.read_csv(\"/content/kaggle/sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pUZiI-gPcz0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train['comment_text'] = train['comment_text'].astype(str)\n",
        "test['comment_text'] = test['comment_text'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGvHNqx5dRg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_text = list(train['comment_text'].values) + list(test['comment_text'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bKVzzoldUU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tk = Tokenizer(lower = True, filters='', num_words=30000)\n",
        "tk.fit_on_texts(full_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDTI1JRUeJBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_tokenized = tk.texts_to_sequences(train['comment_text'])\n",
        "test_tokenized = tk.texts_to_sequences(test['comment_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcghYmEKeNCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len = 550\n",
        "X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
        "X_test = pad_sequences(test_tokenized, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6RHdILFe58q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HMF0ZpwZf6eI",
        "colab_type": "code",
        "outputId": "deca2ec4-fac5-4f10-8fa7-f0326b23e110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lZ6YTb0_gvqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = \"/content/drive/My Drive/Colab Notebooks/Kaggle/glove.6B.300d.txt\"\n",
        "# /kaggle/input/embeddings/glove.840B.300d/glove.840B.300d.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0UKpS3Qg7BE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "max_features = 30000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83VaOqzchCNc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
        "\n",
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GndNDJDhh3TI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.where(train['target'] >= 0.5, True, False) * 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CK7g70FSI99c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = train['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sNmNtyth8Wu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(lr=0.0, lr_d=0.0, spatial_dr=0.0,  dense_units=128, dr=0.1):\n",
        "    file_path = \"best_model.hdf5\"\n",
        "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                  save_best_only = True, mode = \"min\")\n",
        "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "    \n",
        "    inp = Input(shape = (max_len,))\n",
        "    \n",
        "    x = Embedding(max_features +1, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x=  Bidirectional(LSTM(units=100,return_sequences=True,recurrent_dropout=0.24))(x)\n",
        "    x=  Bidirectional(LSTM(units=50,recurrent_dropout=0.14,return_sequences=True))(x)\n",
        "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
        "    # from benchmark kernel\n",
        "    x = Conv1D(128, 2, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling1D(5, padding='same')(x)\n",
        "    x = Conv1D(228, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling1D(5, padding='same')(x)\n",
        "    x = Conv1D(328, 4, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling1D(40, padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
        "    x = Dense(1)(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    model.compile(loss = \"mae\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit(X_train, y, batch_size = 500, epochs = 1, validation_split=0.2, \n",
        "                        verbose = 1, callbacks = [check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27lFAquwjavV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_model(lr = 1e-2, lr_d = 1e-10, spatial_dr = 0.1, dr=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4CsN-GPAJWrC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from subprocess import check_output\n",
        "pred = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
        "sub['prediction'] = pred\n",
        "sub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}